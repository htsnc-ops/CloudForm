---
# Source: cloudform/charts/keycloak/templates/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: release-name-keycloak
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: keycloak
    app.kubernetes.io/version: 23.0.7
    helm.sh/chart: keycloak-18.7.1
    app.kubernetes.io/component: keycloak
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: keycloak
      app.kubernetes.io/component: keycloak
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 7800
        - port: 8080
---
# Source: cloudform/templates/networkpolicy.yaml
# Network Policy for Portal API
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: release-name-cloudform-api
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: cloudform
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: api
  policyTypes:
    - Ingress
    - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: harbortech
    - podSelector:
        matchLabels:
          app.kubernetes.io/name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: harbortech
    - namespaceSelector:
        matchLabels:
          name: cloudform-containers
    ports:
    - protocol: TCP
      port: 5432  # PostgreSQL
    - protocol: TCP
      port: 8080  # Keycloak
    - protocol: TCP
      port: 8200  # Vault
  - to:
    - namespaceSelector: {}
      podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53
  - to:
    - podSelector: {}
    ports:
    - protocol: TCP
      port: 443  # Kubernetes API
---
# Source: cloudform/templates/networkpolicy.yaml
# Network Policy for Terminal Service
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: release-name-cloudform-terminal
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: cloudform
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: terminal
  policyTypes:
    - Ingress
    - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: harbortech
    - podSelector:
        matchLabels:
          app.kubernetes.io/name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8081
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: cloudform-containers
    ports:
    - protocol: TCP
      port: 65533  # Allow exec into containers
  - to:
    - namespaceSelector: {}
      podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53
  - to:
    - podSelector: {}
    ports:
    - protocol: TCP
      port: 443  # Kubernetes API
    - protocol: TCP
      port: 8080  # Keycloak for JWT validation
---
# Source: cloudform/templates/networkpolicy.yaml
# Network Policy for Frontend
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: release-name-cloudform-frontend
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: cloudform
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: frontend
  policyTypes:
    - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: harbortech
    - podSelector:
        matchLabels:
          app.kubernetes.io/name: ingress-nginx
    ports:
    - protocol: TCP
      port: 80
---
# Source: cloudform/templates/networkpolicy.yaml
# Network Policy for Client Containers
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: release-name-cloudform-containers
  namespace: cloudform-containers
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: cloudform
      app.kubernetes.io/component: container-runtime
  policyTypes:
    - Ingress
    - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: harbortech
      podSelector:
        matchLabels:
          app.kubernetes.io/component: terminal
    - namespaceSelector:
        matchLabels:
          name: harbortech
      podSelector:
        matchLabels:
          app.kubernetes.io/component: api
  egress:
  # Allow DNS
  - to:
    - namespaceSelector: {}
      podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53
  # Allow external cloud API access
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: TCP
      port: 443
    - protocol: TCP
      port: 80
  # Block access to internal cluster services
  - to:
    - namespaceSelector:
        matchLabels:
          name: harbortech
    ports:
    - protocol: TCP
      port: 5432
---
# Source: cloudform/templates/resourcequota.yaml
# Resource Quota for Container Namespace
apiVersion: v1
kind: ResourceQuota
metadata:
  name: release-name-cloudform-containers
  namespace: cloudform-containers
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  hard:
    requests.cpu: "50"
    requests.memory: 50Gi
    limits.cpu: "100"
    limits.memory: 100Gi
    pods: "100"
    persistentvolumeclaims: "50"
---
# Source: cloudform/templates/resourcequota.yaml
# Limit Range for Container Namespace
apiVersion: v1
kind: LimitRange
metadata:
  name: release-name-cloudform-containers
  namespace: cloudform-containers
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  limits:
  - max:
      cpu: "2"
      memory: 2Gi
    min:
      cpu: "100m"
      memory: 128Mi
    default:
      cpu: "500m"
      memory: 512Mi
    defaultRequest:
      cpu: "250m"
      memory: 256Mi
    type: Container
  - max:
      cpu: "4"
      memory: 4Gi
    min:
      cpu: "100m"
      memory: 128Mi
    type: Pod
---
# Source: cloudform/templates/poddisruptionbudget.yaml
# PodDisruptionBudget for Portal API
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: release-name-cloudform-api
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: cloudform
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: api
---
# Source: cloudform/templates/poddisruptionbudget.yaml
# PodDisruptionBudget for Terminal Service
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: release-name-cloudform-terminal
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: cloudform
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: terminal
---
# Source: cloudform/charts/vault/templates/injector-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-vault-agent-injector
  namespace: harbortech
  labels:
    app.kubernetes.io/name: vault-agent-injector
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
---
# Source: cloudform/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: app-admin-sa
  namespace: harbortech
---
# Source: cloudform/charts/keycloak/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-postgresql
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.4.6
type: Opaque
data:
  postgres-password: "cXhaZFp3Snl4dg=="
  password: "a2V5Y2xvYWsxMjM="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: cloudform/charts/keycloak/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-keycloak
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: keycloak
    app.kubernetes.io/version: 23.0.7
    helm.sh/chart: keycloak-18.7.1
    app.kubernetes.io/component: keycloak
type: Opaque
data:
  admin-password: "Y2hhbmdlbWUxMjM="
---
# Source: cloudform/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-postgresql
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.4.4
type: Opaque
data:
  postgres-password: "cVlvTExXZW1sUg=="
  password: "Y2xvdWRwb3J0YWwxMjM="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: cloudform/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-cloudform-secrets
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  database-url: "postgresql://cloudportal:cloudportal123@release-name-postgresql:5432/cloudportal"
  keycloak-client-secret: "change-me-in-production"
  vault-token: "change-me-in-production"
  ## Convert to external secret
---
# Source: cloudform/charts/keycloak/templates/configmap-env-vars.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-keycloak-env-vars
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: keycloak
    app.kubernetes.io/version: 23.0.7
    helm.sh/chart: keycloak-18.7.1
    app.kubernetes.io/component: keycloak
data:
  KEYCLOAK_ADMIN: "admin"
  KEYCLOAK_HTTP_PORT: "8080"
  KEYCLOAK_PROXY: "passthrough"
  KEYCLOAK_ENABLE_STATISTICS: "false"
  KEYCLOAK_DATABASE_HOST: "release-name-postgresql"
  KEYCLOAK_DATABASE_PORT: "5432"
  KEYCLOAK_DATABASE_NAME: "keycloak"
  KEYCLOAK_DATABASE_USER: "keycloak"
  KEYCLOAK_PRODUCTION:  "false"
  KEYCLOAK_ENABLE_HTTPS: "false"
  KEYCLOAK_CACHE_TYPE: "ispn"
  KEYCLOAK_CACHE_STACK: "kubernetes"
  JAVA_OPTS_APPEND: "-Djgroups.dns.query=release-name-keycloak-headless.harbortech.svc.cluster.local"
  KEYCLOAK_LOG_OUTPUT: "default"
  KEYCLOAK_LOG_LEVEL: "INFO"
---
# Source: cloudform/charts/vault/templates/server-config-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-vault-config
  namespace: harbortech
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  extraconfig-from-values.hcl: |-
    disable_mlock = true
    ui = true
    listener "tcp" {
      tls_disable = 1
      address = "[::]:8200"
      cluster_address = "[::]:8201"
    }
    storage "file" {
      path = "/vault/data"
    }
---
# Source: cloudform/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-cloudform-config
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
data:
  container-images.json: |
    {
      "azure": "mcr.microsoft.com/azure-cli:latest",
      "aws": "amazon/aws-cli:latest",
      "gcp": "google/cloud-sdk:latest"
    }
  container-resources.json: |
    {
      "requests": {
        "memory": "256Mi",
        "cpu": "250m"
      },
      "limits": {
        "memory": "512Mi",
        "cpu": "500m"
      }
    }
  timeouts.json: |
    {
      "default": 3600,
      "idle": 900,
      "cleanup": 300
    }
---
# Source: cloudform/charts/vault/templates/injector-clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: release-name-vault-agent-injector-clusterrole
  labels:
    app.kubernetes.io/name: vault-agent-injector
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: ["admissionregistration.k8s.io"]
  resources: ["mutatingwebhookconfigurations"]
  verbs:
    - "get"
    - "list"
    - "watch"
    - "patch"
---
# Source: cloudform/templates/rbac/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: release-name-full-access
  labels:
    app.kubernetes.io/name: "cloudform"
    app.kubernetes.io/instance: "release-name"
rules:
  - apiGroups:
      - "*"
    resources:
      - "*"
    verbs:
      - "*"
---
# Source: cloudform/charts/vault/templates/injector-clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: release-name-vault-agent-injector-binding
  labels:
    app.kubernetes.io/name: vault-agent-injector
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: release-name-vault-agent-injector-clusterrole
subjects:
- kind: ServiceAccount
  name: release-name-vault-agent-injector
  namespace: harbortech
---
# Source: cloudform/charts/vault/templates/server-clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: release-name-vault-server-binding
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:auth-delegator
subjects:
- kind: ServiceAccount
  name: cloudform-shared-sa
  namespace: harbortech
---
# Source: cloudform/templates/rbac/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: release-name-full-access-binding
  labels:
    app.kubernetes.io/name: "cloudform"
    app.kubernetes.io/instance: "release-name"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: release-name-full-access
subjects:
---
# Source: cloudform/templates/serviceaccount.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: app-admin-sa-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: app-admin-sa
    namespace: harbortech
---
# Source: cloudform/templates/rbac/role.yaml
# Role for Portal API in main namespace
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-full-access
  namespace: harbortech
  labels:
    app.kubernetes.io/name: "cloudform"
    app.kubernetes.io/instance: "release-name"
rules:
  - apiGroups:
      - "*"
    resources:
      - "*"
    verbs:
      - "*"
---
# Source: cloudform/templates/rbac/rolebinding.yaml
# Bind Portal API to its role in main namespace
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-full-access-binding
  labels:
    app.kubernetes.io/name: "cloudform"
    app.kubernetes.io/instance: "release-name"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: release-name-full-access
subjects:
---
# Source: cloudform/charts/keycloak/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql-hl
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.4.6
    app.kubernetes.io/component: primary
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: cloudform/charts/keycloak/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.4.6
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: cloudform/charts/keycloak/templates/headless-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-keycloak-headless
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: keycloak
    app.kubernetes.io/version: 23.0.7
    helm.sh/chart: keycloak-18.7.1
    app.kubernetes.io/component: keycloak
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: http
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: keycloak
    app.kubernetes.io/component: keycloak
---
# Source: cloudform/charts/keycloak/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-keycloak
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: keycloak
    app.kubernetes.io/version: 23.0.7
    helm.sh/chart: keycloak-18.7.1
    app.kubernetes.io/component: keycloak
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: http
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: keycloak
    app.kubernetes.io/component: keycloak
---
# Source: cloudform/charts/postgresql/templates/primary/metrics-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql-metrics
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.4.4
    app.kubernetes.io/component: metrics
  annotations:
    prometheus.io/port: "9187"
    prometheus.io/scrape: "true"
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: http-metrics
      port: 9187
      targetPort: http-metrics
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: cloudform/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql-hl
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.4.4
    app.kubernetes.io/component: primary
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: cloudform/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.4.4
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: cloudform/charts/vault/templates/injector-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-vault-agent-injector-svc
  namespace: harbortech
  labels:
    app.kubernetes.io/name: vault-agent-injector
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  
spec:
  ports:
  - name: https
    port: 443
    targetPort: 8080
  selector:
    app.kubernetes.io/name: vault-agent-injector
    app.kubernetes.io/instance: release-name
    component: webhook
---
# Source: cloudform/charts/vault/templates/server-headless-service.yaml
# Service for Vault cluster
apiVersion: v1
kind: Service
metadata:
  name: release-name-vault-internal
  namespace: harbortech
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    vault-internal: "true"
  annotations:

spec:
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: "http"
      port: 8200
      targetPort: 8200
    - name: https-internal
      port: 8201
      targetPort: 8201
  selector:
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: release-name
    component: server
---
# Source: cloudform/charts/vault/templates/server-service.yaml
# Service for Vault cluster
apiVersion: v1
kind: Service
metadata:
  name: release-name-vault
  namespace: harbortech
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:

spec:
  # We want the servers to become available even if they're not ready
  # since this DNS is also used for join operations.
  publishNotReadyAddresses: true
  ports:
    - name: http
      port: 8200
      targetPort: 8200
    - name: https-internal
      port: 8201
      targetPort: 8201
  selector:
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: release-name
    component: server
---
# Source: cloudform/charts/vault/templates/ui-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-vault-ui
  namespace: harbortech
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault-ui
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: release-name
    component: server
  publishNotReadyAddresses: true
  ports:
    - name: http
      port: 8200
      targetPort: 8200
  type: ClusterIP
---
# Source: cloudform/templates/frontend/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-cloudform-frontend
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: frontend
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: http
    protocol: TCP
    name: http
  selector:
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: frontend
---
# Source: cloudform/templates/portal-api/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-cloudform-api
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: api
spec:
  type: ClusterIP
  ports:
  - port: 8080
    targetPort: http
    protocol: TCP
    name: http
  selector:
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: api
---
# Source: cloudform/templates/terminal-service/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-cloudform-terminal
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: terminal
spec:
  type: ClusterIP
  ports:
  - port: 8081
    targetPort: ws
    protocol: TCP
    name: ws
  selector:
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: terminal
---
# Source: cloudform/charts/vault/templates/injector-deployment.yaml
# Deployment for the injector
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-vault-agent-injector
  namespace: harbortech
  labels:
    app.kubernetes.io/name: vault-agent-injector
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    component: webhook
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: vault-agent-injector
      app.kubernetes.io/instance: release-name
      component: webhook
  
  template:
    metadata:
      labels:
        app.kubernetes.io/name: vault-agent-injector
        app.kubernetes.io/instance: release-name
        component: webhook
    spec:
      
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app.kubernetes.io/name: vault-agent-injector
                  app.kubernetes.io/instance: "release-name"
                  component: webhook
              topologyKey: kubernetes.io/hostname
  
      
      
      
      serviceAccountName: "release-name-vault-agent-injector"
      
      securityContext:
        runAsNonRoot: true
        runAsGroup: 1000
        runAsUser: 100
        fsGroup: 1000
      hostNetwork: false
      containers:
        - name: sidecar-injector
          
          image: "hashicorp/vault-k8s:1.3.1"
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          env:
            - name: AGENT_INJECT_LISTEN
              value: :8080
            - name: AGENT_INJECT_LOG_LEVEL
              value: info
            - name: AGENT_INJECT_VAULT_ADDR
              value: http://release-name-vault.harbortech.svc:8200
            - name: AGENT_INJECT_VAULT_AUTH_PATH
              value: auth/kubernetes
            - name: AGENT_INJECT_VAULT_IMAGE
              value: "hashicorp/vault:1.15.2"
            - name: AGENT_INJECT_TLS_AUTO
              value: release-name-vault-agent-injector-cfg
            - name: AGENT_INJECT_TLS_AUTO_HOSTS
              value: release-name-vault-agent-injector-svc,release-name-vault-agent-injector-svc.harbortech,release-name-vault-agent-injector-svc.harbortech.svc
            - name: AGENT_INJECT_LOG_FORMAT
              value: standard
            - name: AGENT_INJECT_REVOKE_ON_SHUTDOWN
              value: "false"
            - name: AGENT_INJECT_CPU_REQUEST
              value: "250m"
            - name: AGENT_INJECT_CPU_LIMIT
              value: "500m"
            - name: AGENT_INJECT_MEM_REQUEST
              value: "64Mi"
            - name: AGENT_INJECT_MEM_LIMIT
              value: "128Mi"
            - name: AGENT_INJECT_DEFAULT_TEMPLATE
              value: "map"
            - name: AGENT_INJECT_TEMPLATE_CONFIG_EXIT_ON_RETRY_FAILURE
              value: "true"
            
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          args:
            - agent-inject
            - 2>&1
          livenessProbe:
            httpGet:
              path: /health/ready
              port: 8080
              scheme: HTTPS
            failureThreshold: 2
            initialDelaySeconds: 5
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            httpGet:
              path: /health/ready
              port: 8080
              scheme: HTTPS
            failureThreshold: 2
            initialDelaySeconds: 5
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 5
          startupProbe:
            httpGet:
              path: /health/ready
              port: 8080
              scheme: HTTPS
            failureThreshold: 12
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 5
---
# Source: cloudform/templates/frontend/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-cloudform-frontend
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: frontend
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: cloudform
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: frontend
  template:
    metadata:
      labels:
        app.kubernetes.io/name: cloudform
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/component: frontend
    spec:
      securityContext:
        fsGroup: 1000
        runAsNonRoot: true
        runAsUser: 1000
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: frontend
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
        image: "ghcr.io/htsnc-ops/cloudform-api:1.0.4"
        imagePullPolicy: IfNotPresent
        ports:
        - name: http
          containerPort: 80
          protocol: TCP
        env:
        - name: API_URL
          value: "/api"
        - name: WS_URL
          value: "/ws"
        resources:
          limits:
            cpu: 200m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
        volumeMounts:
        - name: run
          mountPath: /run
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /var/cache/nginx
      volumes:
      - name: run
        emptyDir: {}
      - name: tmp
        emptyDir: {}
      - name: cache
        emptyDir: {}
---
# Source: cloudform/templates/portal-api/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-cloudform-api
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: api
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: cloudform
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: api
  template:
    metadata:
      labels:
        app.kubernetes.io/name: cloudform
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/component: api
      annotations:
        checksum/config: 935d397eb8adc5e9a250ef2ed59f1ffdd040fd170efced6b69825f7ea3fec759
    spec:
      serviceAccountName: 
      securityContext:
        fsGroup: 1000
        runAsNonRoot: true
        runAsUser: 1000
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: api
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
        image: "ghcr.io/htsnc-ops/cloudform-api:1.0.4"
        imagePullPolicy: IfNotPresent
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        env:
        - name: PORT
          value: "8080"
        - name: LOG_LEVEL
          value: "info"
        - name: SESSION_TIMEOUT
          value: "3600"
        - name: MAX_CONTAINERS_PER_USER
          value: "5"
        - name: CONTAINER_NAMESPACE
          value: "cloudform-containers"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: release-name-cloudform-secrets
              key: database-url
        - name: KEYCLOAK_URL
          value: "http://release-name-keycloak:8080"
        - name: KEYCLOAK_REALM
          value: "cloudform"
        - name: KEYCLOAK_CLIENT_ID
          value: "cloudform-api"
        - name: KEYCLOAK_CLIENT_SECRET
          valueFrom:
            secretKeyRef:
              name: release-name-cloudform-secrets
              key: keycloak-client-secret
        - name: VAULT_ADDR
          value: "http://release-name-vault:8200"
        - name: VAULT_TOKEN
          valueFrom:
            secretKeyRef:
              name: release-name-cloudform-secrets
              key: vault-token
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
        resources:
          limits:
            cpu: 500m
            memory: 512Mi
          requests:
            cpu: 250m
            memory: 256Mi
        volumeMounts:
        - name: tmp
          mountPath: /tmp
      volumes:
      - name: tmp
        emptyDir: {}
---
# Source: cloudform/templates/terminal-service/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-cloudform-terminal
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: terminal
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: cloudform
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: terminal
  template:
    metadata:
      labels:
        app.kubernetes.io/name: cloudform
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/component: terminal
    spec:
      serviceAccountName: 
      securityContext:
        fsGroup: 1000
        runAsNonRoot: true
        runAsUser: 1000
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: terminal
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
        image: "ghcr.io/htsnc-ops/cloudform-terminal:1.0.4"
        imagePullPolicy: IfNotPresent
        ports:
        - name: ws
          containerPort: 8081
          protocol: TCP
        env:
        - name: WS_PORT
          value: "8081"
        - name: WS_PATH
          value: "/ws/terminal"
        - name: LOG_LEVEL
          value: "info"
        - name: HEARTBEAT_INTERVAL
          value: "30000"
        - name: CONNECTION_TIMEOUT
          value: "300000"
        - name: MAX_CONNECTIONS_PER_POD
          value: "100"
        - name: KUBERNETES_SERVICE_HOST
          value: "kubernetes.default.svc"
        - name: KUBERNETES_SERVICE_PORT
          value: "443"
        - name: CONTAINER_NAMESPACE
          value: "cloudform-containers"
        - name: JWT_PUBLIC_KEY_URL
          value: "http://release-name-keycloak:8080/realms/cloudform/protocol/openid-connect/certs"
        resources:
          limits:
            cpu: 500m
            memory: 512Mi
          requests:
            cpu: 250m
            memory: 256Mi
        volumeMounts:
        - name: tmp
          mountPath: /tmp
      volumes:
      - name: tmp
        emptyDir: {}
---
# Source: cloudform/templates/portal-api/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: release-name-cloudform-api
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: api
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: release-name-cloudform-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
---
# Source: cloudform/charts/keycloak/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-postgresql
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.4.6
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: release-name-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: release-name-postgresql
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/version: 16.1.0
        helm.sh/chart: postgresql-13.4.6
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: cloudform-shared-sa
      
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: registry-1.docker.io/bitnami/postgresql:16.1.0-debian-11-r25
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "keycloak"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "keycloak"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "keycloak" -d "dbname=keycloak" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "keycloak" -d "dbname=keycloak" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
        storageClassName: standard
---
# Source: cloudform/charts/keycloak/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-keycloak
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: keycloak
    app.kubernetes.io/version: 23.0.7
    helm.sh/chart: keycloak-18.7.1
    app.kubernetes.io/component: keycloak
spec:
  replicas: 1
  revisionHistoryLimit: 10
  podManagementPolicy: Parallel
  serviceName: release-name-keycloak-headless
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: keycloak
      app.kubernetes.io/component: keycloak
  template:
    metadata:
      annotations:
        checksum/configmap-env-vars: 6498446d2329377833e8b8335c8b011e6116ae29075100613783ddac520a413d
        checksum/secrets: 8a4384d47ec3cbdbadcbc3b0c629eb641dfc472d1d3eff081ee296070938f9c4
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: keycloak
        app.kubernetes.io/version: 23.0.7
        helm.sh/chart: keycloak-18.7.1
        app.kubernetes.io/component: keycloak
    spec:
      serviceAccountName: cloudform-shared-sa
      
      automountServiceAccountToken: true
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: keycloak
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      enableServiceLinks: true
      initContainers:
      containers:
        - name: keycloak
          image: docker.io/bitnami/keycloak:23.0.7-debian-12-r0
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: null
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: KUBERNETES_NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: BITNAMI_DEBUG
              value: "false"
            - name: KEYCLOAK_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-keycloak
                  key: admin-password
            - name: KEYCLOAK_DATABASE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: password
            - name: KEYCLOAK_HTTP_RELATIVE_PATH
              value: "/"
            - name: KEYCLOAK_EXTRA_ARGS
              value: --import-realm
          envFrom:
            - configMapRef:
                name: release-name-keycloak-env-vars
          resources:
            limits:
              cpu: 1000m
              memory: 1Gi
            requests:
              cpu: 500m
              memory: 512Mi
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
            - name: infinispan
              containerPort: 7800
              protocol: TCP
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 300
            periodSeconds: 1
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /
              port: http
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
            httpGet:
              path: /realms/master
              port: http
          volumeMounts:
      volumes:
---
# Source: cloudform/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-postgresql
  namespace: "harbortech"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.4.4
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: release-name-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: release-name-postgresql
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/version: 16.1.0
        helm.sh/chart: postgresql-13.4.4
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: cloudform-shared-sa
      
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:16.1.0-debian-11-r25
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: null
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "cloudportal"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "cloudportal"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "cloudportal" -d "dbname=cloudportal" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "cloudportal" -d "dbname=cloudportal" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
        - name: metrics
          image: docker.io/bitnami/postgres-exporter:0.15.0-debian-11-r7
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: null
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: DATA_SOURCE_URI
              value: 127.0.0.1:5432/cloudportal?sslmode=disable
            - name: DATA_SOURCE_PASS
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: password
            - name: DATA_SOURCE_USER
              value: "cloudportal"
          ports:
            - name: http-metrics
              containerPort: 9187
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /
              port: http-metrics
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /
              port: http-metrics
          volumeMounts:
          resources:
            limits: {}
            requests: {}
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "20Gi"
        storageClassName: standard
---
# Source: cloudform/charts/vault/templates/server-statefulset.yaml
# StatefulSet to run the actual vault server cluster.
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-vault
  namespace: harbortech
  labels:
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  serviceName: release-name-vault-internal
  podManagementPolicy: Parallel
  replicas: 1
  updateStrategy:
    type: OnDelete
  selector:
    matchLabels:
      app.kubernetes.io/name: vault
      app.kubernetes.io/instance: release-name
      component: server
  template:
    metadata:
      labels:
        helm.sh/chart: vault-0.27.0
        app.kubernetes.io/name: vault
        app.kubernetes.io/instance: release-name
        component: server
    spec:
      
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app.kubernetes.io/name: vault
                  app.kubernetes.io/instance: "release-name"
                  component: server
              topologyKey: kubernetes.io/hostname
  
      
      
      
      terminationGracePeriodSeconds: 10
      serviceAccountName: cloudform-shared-sa
      
      securityContext:
        runAsNonRoot: true
        runAsGroup: 1000
        runAsUser: 100
        fsGroup: 1000
      hostNetwork: false
      volumes:
        
        - name: config
          configMap:
            name: release-name-vault-config
  
        - name: home
          emptyDir: {}
      containers:
        - name: vault
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 250m
              memory: 256Mi
  
          image: hashicorp/vault:1.15.2
          imagePullPolicy: IfNotPresent
          command:
          - "/bin/sh"
          - "-ec"
          args: 
          - |
            cp /vault/config/extraconfig-from-values.hcl /tmp/storageconfig.hcl;
            [ -n "${HOST_IP}" ] && sed -Ei "s|HOST_IP|${HOST_IP?}|g" /tmp/storageconfig.hcl;
            [ -n "${POD_IP}" ] && sed -Ei "s|POD_IP|${POD_IP?}|g" /tmp/storageconfig.hcl;
            [ -n "${HOSTNAME}" ] && sed -Ei "s|HOSTNAME|${HOSTNAME?}|g" /tmp/storageconfig.hcl;
            [ -n "${API_ADDR}" ] && sed -Ei "s|API_ADDR|${API_ADDR?}|g" /tmp/storageconfig.hcl;
            [ -n "${TRANSIT_ADDR}" ] && sed -Ei "s|TRANSIT_ADDR|${TRANSIT_ADDR?}|g" /tmp/storageconfig.hcl;
            [ -n "${RAFT_ADDR}" ] && sed -Ei "s|RAFT_ADDR|${RAFT_ADDR?}|g" /tmp/storageconfig.hcl;
            /usr/local/bin/docker-entrypoint.sh vault server -config=/tmp/storageconfig.hcl 
   
          securityContext:
            allowPrivilegeEscalation: false
          env:
            - name: HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: VAULT_K8S_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: VAULT_K8S_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: VAULT_ADDR
              value: "http://127.0.0.1:8200"
            - name: VAULT_API_ADDR
              value: "http://$(POD_IP):8200"
            - name: SKIP_CHOWN
              value: "true"
            - name: SKIP_SETCAP
              value: "true"
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: VAULT_CLUSTER_ADDR
              value: "https://$(HOSTNAME).release-name-vault-internal:8201"
            - name: HOME
              value: "/home/vault"
            
            
            
          volumeMounts:
          
  
    
            - name: data
              mountPath: /vault/data
    
  
  
            - name: config
              mountPath: /vault/config
  
            - name: home
              mountPath: /home/vault
          ports:
            - containerPort: 8200
              name: http
            - containerPort: 8201
              name: https-internal
            - containerPort: 8202
              name: http-rep
          readinessProbe:
            # Check status; unsealed vault servers return 0
            # The exit code reflects the seal status:
            #   0 - unsealed
            #   1 - error
            #   2 - sealed
            exec:
              command: ["/bin/sh", "-ec", "vault status -tls-skip-verify"]
            failureThreshold: 2
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          lifecycle:
            # Vault container doesn't receive SIGTERM from Kubernetes
            # and after the grace period ends, Kube sends SIGKILL.  This
            # causes issues with graceful shutdowns such as deregistering itself
            # from Consul (zombie services).
            preStop:
              exec:
                command: [
                  "/bin/sh", "-c",
                  # Adding a sleep here to give the pod eviction a
                  # chance to propagate, so requests will not be made
                  # to this pod while it's terminating
                  "sleep 5 && kill -SIGTERM $(pidof vault)",
                ]
      
  
  volumeClaimTemplates:
    - metadata:
        name: data
      
      
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 10Gi
        storageClassName: standard
---
# Source: cloudform/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: release-name-cloudform
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/websocket-services: terminal-service
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - "cloudform.example.com"
      secretName: cloudform-tls
  rules:
    - host: "cloudform.example.com"
      http:
        paths:
          - path: /api
            pathType: Prefix
            backend:
              service:
                name: release-name-cloudform-api
                port:
                  number: 8080
          - path: /ws
            pathType: Prefix
            backend:
              service:
                name: release-name-cloudform-terminal
                port:
                  number: 8080
          - path: /auth
            pathType: Prefix
            backend:
              service:
                name: release-name-cloudform-keycloak
                port:
                  number: 8080
          - path: /
            pathType: Prefix
            backend:
              service:
                name: release-name-cloudform-frontend
                port:
                  number: 80
---
# Source: cloudform/charts/vault/templates/injector-mutating-webhook.yaml
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: release-name-vault-agent-injector-cfg
  labels:
    app.kubernetes.io/name: vault-agent-injector
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
webhooks:
  - name: vault.hashicorp.com
    failurePolicy: Ignore
    matchPolicy: Exact
    sideEffects: None
    timeoutSeconds: 30
    admissionReviewVersions: ["v1", "v1beta1"]
    clientConfig:
      service:
        name: release-name-vault-agent-injector-svc
        namespace: harbortech
        path: "/mutate"
      caBundle: ""
    rules:
      - operations: ["CREATE", "UPDATE"]
        apiGroups: [""]
        apiVersions: ["v1"]
        resources: ["pods"]
    objectSelector:
      matchExpressions:
      - key: app.kubernetes.io/name
        operator: NotIn
        values:
        - vault-agent-injector
---
# Source: cloudform/templates/monitoring/prometheusrule.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: release-name-cloudform
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  groups:
  - name: cloudform.rules
    interval: 30s
    rules:
    - alert: HighContainerCount
      expr: cloudportal_active_containers > 50
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High number of active containers
    - alert: HighAPILatency
      expr: cloudportal_api_request_duration_seconds > 1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: API response time is high
---
# Source: cloudform/templates/monitoring/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: release-name-cloudform-api
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: cloudform
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: api
  endpoints:
  - port: http
    path: /metrics
    interval: 30s
---
# Source: cloudform/templates/monitoring/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: release-name-cloudform-terminal
  namespace: harbortech
  labels:
    helm.sh/chart: cloudform-1.0.0
    app.kubernetes.io/name: cloudform
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: cloudform
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: terminal
  endpoints:
  - port: ws
    path: /metrics
    interval: 30s
---
# Source: cloudform/charts/vault/templates/tests/server-test.yaml
apiVersion: v1
kind: Pod
metadata:
  name: release-name-vault-server-test
  namespace: harbortech
  annotations:
    "helm.sh/hook": test
spec:
  
  containers:
    - name: release-name-server-test
      image: hashicorp/vault:1.15.2
      imagePullPolicy: IfNotPresent
      env:
        - name: VAULT_ADDR
          value: http://release-name-vault.harbortech.svc:8200
        
      command:
        - /bin/sh
        - -c
        - |
          echo "Checking for sealed info in 'vault status' output"
          ATTEMPTS=10
          n=0
          until [ "$n" -ge $ATTEMPTS ]
          do
            echo "Attempt" $n...
            vault status -format yaml | grep -E '^sealed: (true|false)' && break
            n=$((n+1))
            sleep 5
          done
          if [ $n -ge $ATTEMPTS ]; then
            echo "timed out looking for sealed info in 'vault status' output"
            exit 1
          fi

          exit 0
      volumeMounts:
  volumes:
  restartPolicy: Never
